{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Rental Problem\n",
    "\n",
    "### Exercise 4.7 (programming)\n",
    "\n",
    "Write a program for policy iteration and re-solve Jack’s car\n",
    "rental problem with the following changes. One of Jack’s employees at the first location\n",
    "rides a bus home each night and lives near the second location. She is happy to shuttle\n",
    "one car to the second location for free. Each additional car still costs 2, as do all cars\n",
    "moved in the other direction. In addition, Jack has limited parking space at each location.\n",
    "If more than 10 cars are kept overnight at a location (after any moving of cars), then an\n",
    "additional cost of 4 must be incurred to use a second parking lot (independent of how\n",
    "many cars are kept there). These sorts of nonlinearities and arbitrary dynamics often\n",
    "occur in real problems and cannot easily be handled by optimization methods other than\n",
    "dynamic programming. To check your program, first replicate the results given for the\n",
    "original problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve problem as presented in Ex4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at <ipython-input-3-b2fa3352ebff> (112)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-3-b2fa3352ebff>\", line 112:\u001b[0m\n\u001b[1mdef improve_policy(pi, v, dynamics):\n    <source elided>\n    \"\"\"\n\u001b[1m    lookback = 5\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\nThis error may have been caused by the following argument(s):\n- argument 2: \u001b[1mCannot determine Numba type of <class 'dict'>\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b2fa3352ebff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mdynamics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPI\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimprove_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xieji\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0merror_rewrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'typing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xieji\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at <ipython-input-3-b2fa3352ebff> (112)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-3-b2fa3352ebff>\", line 112:\u001b[0m\n\u001b[1mdef improve_policy(pi, v, dynamics):\n    <source elided>\n    \"\"\"\n\u001b[1m    lookback = 5\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\nThis error may have been caused by the following argument(s):\n- argument 2: \u001b[1mCannot determine Numba type of <class 'dict'>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from scipy.special import factorial\n",
    "\n",
    "\"\"\"\n",
    "Parameters:\n",
    "n_cars:        Max #cars allowed at each lot\n",
    "n_cars_mv:     Max #cars moved between lots each step\n",
    "V:             Initial state-value function\n",
    "PI:            Initial policy\n",
    "theta:         Policy evaluation convergence constant\n",
    "gamma:         Return discount parameter\n",
    "lambda_req:    Parameters for car request poisson r.v.\n",
    "lambda_ret:    Parameters for car return poisson r.v.\n",
    "\"\"\"\n",
    "n_cars1 = 20\n",
    "n_cars2 = 20\n",
    "n_cars_mv = 5\n",
    "V = np.zeros((n_cars1+1, n_cars2+1))\n",
    "PI = np.zeros((n_cars1+1, n_cars2+1), dtype=int)\n",
    "theta = 0.00001\n",
    "gamma = 0.9\n",
    "lambda_req = [3,4]\n",
    "lambda_ret = [3,2]\n",
    "\n",
    "PICKLE_DIR = \"RL_ex4_7_data\"\n",
    "\n",
    "def evaluate_policy(pi, v):\n",
    "    \"\"\"\n",
    "    Evaluate a policy by determining expected returns at each state.\n",
    "    \n",
    "    Intuitively, the value at each state is updated to reflect \n",
    "        the new policy's action at the current state.\n",
    "    This implementation does not sum over environment probabilities, \n",
    "        but instead uses the mean of poisson random variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        pi : ndarray(shape=(n_cars1+1,n_cars2+1), dtype=int)\n",
    "            Policy to be evaluated \n",
    "        v : ndarray(shape=(n_cars1+1,n_cars2+1), dtype = float)\n",
    "            Current state-value function\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray \n",
    "        State-value function after evaluating pi\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for i in range(n_cars1+1):\n",
    "            for j in range(n_cars2+1):\n",
    "                v_old = v[i,j]\n",
    "                a = pi[i,j]\n",
    "                i_day = max(i-a, 0)\n",
    "                j_day = max(j+a, 0)\n",
    "                reward = 10 * (min(i_day, lambda_req[0]) +\n",
    "                               min(j_day, lambda_req[1])) - 2 * abs(a)\n",
    "                if (a > 0):\n",
    "                    reward += 2\n",
    "                reward += (0 if ((i - a) <= 10) else -4)\n",
    "                reward += (0 if ((j + a) <= 10) else -4)\n",
    "                i_p = min(max(i_day-lambda_req[0], 0) + lambda_ret[0], n_cars1)\n",
    "                j_p = min(max(j_day-lambda_req[1], 0) + lambda_ret[1], n_cars2)\n",
    "                s_p = [i_p, j_p]\n",
    "                v[i,j] = reward + gamma * v[s_p[0],s_p[1]]\n",
    "                delta = max(delta, np.abs(v[i,j]-v_old))\n",
    "        if (delta < theta):\n",
    "            return v\n",
    "\n",
    "def improve_policy(pi, v, dynamics):\n",
    "    \"\"\"\n",
    "    Updates policy greedily w.r.t. to previously calculated state-values.\n",
    "    \n",
    "    For each state, the new policy chooses the action \n",
    "        that gives the highest expected returns.\n",
    "    Uses a dictionary to lookup environment dynamics for state-action\n",
    "    Checks policy stability via lookback. If a state-value function has been seen before,\n",
    "        then the policy is stable\n",
    "    Multiple optimal policies are possible, hence the lookback to prevent infinite loops\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "        pi : ndarray(shape=(n_cars1+1,n_cars2+1), dtype=int)\n",
    "            Policy to be improved\n",
    "        v : ndarray(shape=(n_cars1+1,n_cars2+1), dtype = float)\n",
    "            Current state-value function\n",
    "        dynamics : dict\n",
    "            Environment dynamics\n",
    "            f(s'r|s,a) = p(s',r|s,a) = { (s,a): { (s',r): y } }\n",
    "    Returns\n",
    "    -------\n",
    "        (ndarray, ndarray)\n",
    "        Optimal policies and state-value functions\n",
    "    \"\"\"\n",
    "    lookback = 5\n",
    "    policies = []\n",
    "    reward_rec = []\n",
    "    \n",
    "    while True:\n",
    "        policy_stable = True\n",
    "        for i in range(n_cars1+1):\n",
    "            for j in range(n_cars2+1):\n",
    "                if (i != 0 or j != 0):\n",
    "                    \n",
    "                    actions = np.arange(-min(n_cars_mv,j), \n",
    "                                        min(n_cars_mv,i) + 1, 1, \n",
    "                                        dtype=float)\n",
    "                    actions = actions[np.where(\n",
    "                                    (actions <= i) & \n",
    "                                    (-actions <= j) & \n",
    "                                    (-actions + i <= n_cars1) & \n",
    "                                    (actions + j <= n_cars2))]\n",
    "                    action_returns = np.zeros(actions.size)\n",
    "                    for n, a in enumerate(actions):\n",
    "                        cond_dynamics = dynamics[(i, j, a)]\n",
    "                        action_return = 0\n",
    "                        for k in cond_dynamics.keys():\n",
    "                            action_return += cond_dynamics[k] * (k[2] + \n",
    "                                                                 gamma * \n",
    "                                                                 v[k[0], k[1]])\n",
    "                        action_returns[n] = action_return\n",
    "\n",
    "                    pi[i,j] = actions[np.argmax(action_returns)]\n",
    "        \n",
    "        v = evaluate_policy(pi, v)\n",
    "        if (round(np.sum(v), 1) not in reward_rec):\n",
    "            plt.figure()\n",
    "            plt.imshow(pi, origin='lower')\n",
    "            plt.show()\n",
    "            policy_stable = False\n",
    "            policies.append(pi)\n",
    "            reward_rec.append(round(np.sum(v), 1))\n",
    "            if (len(policies) > lookback):\n",
    "                policies.pop(0)\n",
    "                reward_rec.pop(0)\n",
    "\n",
    "        if policy_stable:\n",
    "            return (policies, v)\n",
    "\n",
    "def eval_poisson(l, n):\n",
    "    \"\"\"\n",
    "    Evaluates probability P(n) according to poisson(l) distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        l : list\n",
    "            Poisson parameters\n",
    "        n : list\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        ndarray\n",
    "            Probabilities\n",
    "    \"\"\"\n",
    "    return np.maximum(np.repeat(np.finfo(float).eps,len(l)), \n",
    "                      np.abs(np.divide(np.multiply(np.power(l, n), \n",
    "                                                   np.exp(np.multiply(l, -1))), \n",
    "                                       factorial(n))))\n",
    "        \n",
    "def train():\n",
    "    \"\"\"\n",
    "    Calculate environment dynamics\n",
    "    \n",
    "    For each (s',r,s,a), calculate its probability\n",
    "    s' and r are indirectly determined from (reqx,reqy,retx,retx),\n",
    "        the number of requests/returns on each site\n",
    "    (reqx,reqy,retx,rety) makes up a joint distribution of poisson r.v.s\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        dict\n",
    "            f(s'r|s,a) = p(s',r|s,a) = { (s,a): { (s',r): y } }\n",
    "    \"\"\"\n",
    "    all_possibilities = {}\n",
    "    for reqx in range(n_cars1+1):\n",
    "        for reqy in range(n_cars2+1):\n",
    "            for retx in range(n_cars1+1):\n",
    "                for rety in range(n_cars2+1):\n",
    "                    all_possibilities[(reqx, reqy, retx, rety)] = np.prod(eval_poisson([lambda_ret[0], lambda_ret[1], lambda_req[0], lambda_req[1]], \n",
    "                                                                             [retx, rety, reqx, reqy]))\n",
    "\n",
    "    P = {}\n",
    "    for sx in range(n_cars1+1):\n",
    "        print(\"State: {}\".format(sx))\n",
    "        for sy in range(n_cars2+1):\n",
    "            for a in np.arange(-n_cars_mv, n_cars_mv +1, 1, dtype=int):\n",
    "                if a <= sx and -a <= sy and -a + sx <= n_cars1 and a + sy <= n_cars2:\n",
    "                    P[(sx,sy,a)] = {}\n",
    "                    for reqx in range(n_cars1+1):\n",
    "                        for reqy in range(n_cars2+1):\n",
    "                            r = int(10 * min(sx - a, reqx) + 10 * min(sy + a, reqy) - 2 * abs(a))\n",
    "                            if (a > 0):\n",
    "                                r += 2\n",
    "                            if (sx - a > 10):\n",
    "                                r += -4\n",
    "                            if (sy + a > 10):\n",
    "                                r += -4\n",
    "                            for retx in range(n_cars1+1):\n",
    "                                for rety in range(n_cars2+1):\n",
    "                                    sx_p = min(max(sx - a - reqx, 0) + retx, n_cars1)\n",
    "                                    sy_p = min(max(sy + a - reqy, 0) + rety, n_cars2)\n",
    "                                    if (sx_p,sy_p,r) in P[(sx,sy,a)]:\n",
    "                                        P[(sx,sy,a)][(sx_p,sy_p,r)] += all_possibilities[(reqx, reqy, retx, rety)]\n",
    "                                    else:\n",
    "                                        P[(sx,sy,a)][(sx_p,sy_p,r)] = all_possibilities[(reqx, reqy, retx, rety)]\n",
    "\n",
    "    return P\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #dynamics = train()\n",
    "    #if not os.path.isdir(PICKLE_DIR):\n",
    "    #    os.mkdir(PICKLE_DIR)\n",
    "    #with open(PICKLE_DIR + '/dynamicsB.pickle', 'wb') as handle:\n",
    "    #    pickle.dump(dynamics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(PICKLE_DIR + '/dynamicsB.pickle', 'rb') as handle:\n",
    "        dynamics = pickle.load(handle)\n",
    "    v = evaluate_policy(PI,V)\n",
    "    (policies, v) = improve_policy(PI, v, dynamics)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Plot the surface.\n",
    "    X = np.arange(0,n_cars1+1,1)\n",
    "    Y = np.arange(0,n_cars2+1,1)\n",
    "    X, Y = np.meshgrid(X, Y) \n",
    "    surf = ax.plot_surface(X, Y, v, cmap=cm.coolwarm,\n",
    "                           linewidth=0, antialiased=False)\n",
    "\n",
    "    plt.title('Optimal State-Value Function')\n",
    "    plt.xlabel('#Cars at Loc 1')\n",
    "    plt.ylabel('#Cars at Loc 2')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Plot the surface.\n",
    "    X = np.arange(0,n_cars1+1,1)\n",
    "    Y = np.arange(0,n_cars2+1,1)\n",
    "    X, Y = np.meshgrid(X, Y) \n",
    "    surf = ax.plot_surface(X, Y, policies[-1], cmap=cm.coolwarm,\n",
    "                           linewidth=0, antialiased=False)\n",
    "    plt.title('Optimal Policy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
